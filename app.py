import streamlit as st
from streamlit_webrtc import webrtc_stream, WebRtcMode, RTCConfiguration
from google.cloud import speech_v1p1beta1 as speech
from google.cloud.speech_v1p1beta1 import enums
import os
import collections
import time

# --- Google Cloud ì¸ì¦ ì •ë³´ ì„¤ì • ---
# 1. ë¡œì»¬ì—ì„œ ì‹¤í–‰í•  ê²½ìš°: ë‹¤ìš´ë¡œë“œ ë°›ì€ ì„œë¹„ìŠ¤ ê³„ì • JSON í‚¤ íŒŒì¼ ê²½ë¡œ ì§€ì •
# os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "path/to/your/google_cloud_key.json"

# 2. Streamlit Cloudì— ë°°í¬í•  ê²½ìš°: Streamlit Secretsë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¤ì •
#    (secrets.toml íŒŒì¼ì— google_credentials_json = '{"type": "service_account", ...}' í˜•íƒœë¡œ ì €ì¥)
#    st.secrets["google_credentials_json"] ê°’ì„ ì‚¬ìš©í•˜ì—¬ ì¸ì¦í•©ë‹ˆë‹¤.
try:
    if "google_credentials_json" in st.secrets:
        # Streamlit Secretsì—ì„œ ì¸ì¦ ì •ë³´ ë¡œë“œ
        import json
        credentials_json = json.dumps(st.secrets["google_credentials_json"])
        with open("google_credentials.json", "w") as f:
            f.write(credentials_json)
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "google_credentials.json"
    elif "GOOGLE_APPLICATION_CREDENTIALS" not in os.environ:
        st.error("Google Cloud ì¸ì¦ ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                 "Streamlit Secrets ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop() # ì•± ì‹¤í–‰ ì¤‘ë‹¨
except Exception as e:
    st.error(f"Google Cloud ì¸ì¦ ì •ë³´ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()

# --- Streamlit UI ì„¤ì • ---
st.set_page_config(page_title="ì‹¤ì‹œê°„ ëŒ€í™” ë„ìš°ë¯¸", layout="wide")
st.title("ğŸ—£ï¸ ì‹¤ì‹œê°„ ëŒ€í™” ë„ìš°ë¯¸")
st.markdown("ìƒëŒ€ë°©ì˜ ë§ì„ ì‹¤ì‹œê°„ ìë§‰ìœ¼ë¡œ ë³´ê³  ë‰˜ì•™ìŠ¤ê¹Œì§€ í™•ì¸í•˜ì„¸ìš”.")

# --- Google Cloud Speech-to-Text í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
client = speech.SpeechClient()

# ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ì„¤ì •
# ìƒ˜í”Œ ë ˆì´íŠ¸ëŠ” streamlit-webrtcì˜ ê¸°ë³¸ê°’ì¸ 16000Hzì— ë§ì¶°ì¤ë‹ˆë‹¤.
config = speech.RecognitionConfig(
    encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,
    sample_rate_hertz=16000,
    language_code="ko-KR",  # í•œêµ­ì–´ ì„¤ì •
    enable_automatic_punctuation=True,  # ìë™ êµ¬ë‘ì  ì¶”ê°€
    enable_word_time_offsets=True,  # ë‹¨ì–´ë³„ ì‹œê°„ ì˜¤í”„ì…‹ (ë‰˜ì•™ìŠ¤ ë¶„ì„ì— í™œìš© ê°€ëŠ¥)
    use_enhanced=True,  # í–¥ìƒëœ ëª¨ë¸ ì‚¬ìš© (ì •í™•ë„ í–¥ìƒ)
)

streaming_config = speech.StreamingRecognitionConfig(
    config=config,
    interim_results=True,  # ì¤‘ê°„ ê²°ê³¼ í‘œì‹œ
)

# --- ë‰˜ì•™ìŠ¤ ë¶„ì„ í•¨ìˆ˜ ---
def analyze_nuance(text, words_info):
    # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ë‰˜ì•™ìŠ¤ ë¶„ì„ (ê°œì„  í•„ìš”)
    if text.endswith("?"):
        return f"<span style='background-color:#FFFACD;'>**{text}** (ì§ˆë¬¸)</span>"
    elif text.endswith("!"):
        return f"<span style='background-color:#E0FFFF;'>**{text}** (í™•ì‹ /ë™ì˜)</span>"
    elif "ì‘" in text and text.strip() == "ì‘": # 'ì‘' ë‹¨ë… ì‚¬ìš© ì‹œ
        # ë” ë³µì¡í•œ ë‰˜ì•™ìŠ¤ ë¶„ì„ (ì˜ˆ: ì´ì „ ëŒ€í™” ë§¥ë½, ìŒì„± íŠ¹ì§•)ì´ í•„ìš”í•˜ì§€ë§Œ,
        # ì—¬ê¸°ì„œëŠ” êµ¬ë‘ì  ê¸°ë°˜ìœ¼ë¡œë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        return f"**{text}** (ë‰˜ì•™ìŠ¤ íŒŒì•… ì¤‘)"
    return text

# --- ì‹¤ì‹œê°„ ìë§‰ ë° ë‰˜ì•™ìŠ¤ í‘œì‹œ ì˜ì—­ ---
st.markdown("---")
st.subheader("ì‹¤ì‹œê°„ ëŒ€í™” ìë§‰")
current_transcript_placeholder = st.empty()  # ì¤‘ê°„ ê²°ê³¼ë¥¼ í‘œì‹œí•  ì˜ì—­
final_transcript_container = st.container()  # ìµœì¢… ê²°ê³¼ë¥¼ ëˆ„ì  í‘œì‹œí•  ì˜ì—­

# ì´ì „ ìµœì¢… ê²°ê³¼ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
final_transcripts = collections.deque(maxlen=10) # ìµœê·¼ 10ê°œë§Œ ì €ì¥

# --- Streamlit WebRTC ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ---
# WebRTC ì„¤ì • (STUN ì„œë²„ëŠ” NAT traversalì„ ìœ„í•´ í•„ìš”)
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
)

st.info("ì‹œì‘ ë²„íŠ¼ì„ í´ë¦­í•˜ê³  ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.")
st.caption("ì°¸ê³ : Chrome ë¸Œë¼ìš°ì €ì—ì„œ ê°€ì¥ ì˜ ì‘ë™í•©ë‹ˆë‹¤.")

webrtc_ctx = webrtc_stream(
    key="speech-to-text-stream",
    mode=WebRtcMode.SENDONLY,  # ì˜¤ë””ì˜¤ë§Œ ì „ì†¡
    rtc_configuration=RTC_CONFIGURATION,
    media_stream_constraints={"video": False, "audio": True},  # ë¹„ë””ì˜¤ ë¹„í™œì„±í™”, ì˜¤ë””ì˜¤ í™œì„±í™”
    audio_receiver_size=2048,  # ì˜¤ë””ì˜¤ ë²„í¼ í¬ê¸°
    desired_playing_state={"playing": True}, # ì‹œì‘ê³¼ ë™ì‹œì— ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì¬ìƒ ì‹œë„
)

# ì˜¤ë””ì˜¤ ìˆ˜ì‹  ë° STT ì²˜ë¦¬
if webrtc_ctx.audio_receiver:
    st.success("ë§ˆì´í¬ì—ì„œ ìŒì„± ë°ì´í„°ë¥¼ ìˆ˜ì‹  ì¤‘ì…ë‹ˆë‹¤. ë§ì”€í•´ì£¼ì„¸ìš”...")

    # Google Speech-to-Text APIì˜ ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ì„ ìœ„í•œ ì œë„ˆë ˆì´í„°
    # ì˜¤ë””ì˜¤ í”„ë ˆì„ì„ ë°›ì•„ì„œ APIë¡œ ì „ì†¡í•˜ëŠ” ì—­í• 
    def request_generator(audio_receiver):
        # API ìŠ¤íŠ¸ë¦¬ë° ì„¸ì…˜ ìœ ì§€ ì‹œê°„
        # Google Speech-to-Text APIëŠ” ë‹¨ì¼ ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ë‹¹ ì•½ 60ì´ˆì˜ ì œí•œì´ ìˆìŠµë‹ˆë‹¤.
        # ì´ë¥¼ ì´ˆê³¼í•˜ë©´ ìƒˆ ìŠ¤íŠ¸ë¦¬ë° ì„¸ì…˜ì„ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” ê³„ì†í•´ì„œ ì˜¤ë””ì˜¤ë¥¼ ë°›ì•„ì„œ ë³´ë‚´ëŠ” ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        while webrtc_ctx.state.playing: # ì›¹ìº ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ” ë™ì•ˆ ê³„ì† ì‹¤í–‰
            try:
                # audio_receiverì—ì„œ ì˜¤ë””ì˜¤ í”„ë ˆì„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                # get_queued_frames()ëŠ” pydub.AudioSegment ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
                audio_frames = audio_receiver.get_queued_frames(timeout=1) # 1ì´ˆ ëŒ€ê¸°

                if audio_frames:
                    # pydub AudioSegment ë¦¬ìŠ¤íŠ¸ë¥¼ LINEAR16 (RAW) ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ë¡œ ë³€í™˜
                    # Google Speech-to-Text APIëŠ” 16-bit signed, little-endian, mono ì˜¤ë””ì˜¤ë¥¼ ê¸°ëŒ€í•©ë‹ˆë‹¤.
                    # streamlit-webrtcëŠ” ê¸°ë³¸ì ìœ¼ë¡œ 16KHz, 1ì±„ë„, 16bit ì¸ì½”ë”©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
                    audio_bytes = b"".join([frame.to_ndarray().tobytes() for frame in audio_frames])
                    
                    yield speech.StreamingRecognizeRequest(audio_content=audio_bytes)
                else:
                    # ì˜¤ë””ì˜¤ í”„ë ˆì„ì´ ì—†ìœ¼ë©´ ì ì‹œ ëŒ€ê¸°í•˜ì—¬ CPU ì‚¬ìš©ëŸ‰ ì¤„ì„
                    time.sleep(0.01)

            except Exception as e:
                st.warning(f"ì˜¤ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                break # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë£¨í”„ ì¢…ë£Œ

    while webrtc_ctx.state.playing:
        try:
            # ìƒˆë¡œìš´ ìŠ¤íŠ¸ë¦¬ë° ì„¸ì…˜ ì‹œì‘ (60ì´ˆ ì œí•œ ê³ ë ¤)
            requests = request_generator(webrtc_ctx.audio_receiver)
            responses = client.streaming_recognize(streaming_config, requests)

            for response in responses:
                if not response.results:
                    continue

                result = response.results[0]
                if not result.alternatives:
                    continue

                transcript = result.alternatives[0].transcript
                words_info = result.alternatives[0].words

                # ë‰˜ì•™ìŠ¤ ë¶„ì„ ë° í‘œì‹œ
                display_text = analyze_nuance(transcript, words_info)
                current_transcript_placeholder.markdown(f"### {display_text}")

                if result.is_final:
                    # ìµœì¢… ê²°ê³¼ë¥¼ final_transcriptsì— ì¶”ê°€í•˜ê³  í‘œì‹œ ì—…ë°ì´íŠ¸
                    final_transcripts.appendleft(f"- {display_text}")
                    with final_transcript_container:
                        st.markdown("<hr>", unsafe_allow_html=True) # êµ¬ë¶„ì„ 
                        for t in final_transcripts:
                            st.markdown(t, unsafe_allow_html=True)
                    current_transcript_placeholder.empty() # ìµœì¢… ê²°ê³¼ í‘œì‹œ í›„ ì„ì‹œ ìë§‰ ì´ˆê¸°í™”
                    break # í˜„ì¬ ìŠ¤íŠ¸ë¦¬ë° ì„¸ì…˜ì˜ ìµœì¢… ê²°ê³¼ê°€ ë‚˜ì˜¤ë©´ ìƒˆ ì„¸ì…˜ì„ ì‹œì‘
        except Exception as e:
            st.error(f"ìŒì„± ì¸ì‹ ìŠ¤íŠ¸ë¦¼ ì˜¤ë¥˜: {e}")
            st.warning("ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤...")
            time.sleep(2) # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„

else:
    st.warning("ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
